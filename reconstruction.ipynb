{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-04T12:04:55.395979Z",
     "end_time": "2023-04-04T12:04:55.403850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torchvision.utils as vutils\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "\n",
    "# custom\n",
    "from VanillaNet import VanillaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# constants and declarations\n",
    "image_size = 64 # 64x64px\n",
    "dimension = image_size ** 2\n",
    "channels = 1 # grey scale\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "path = \"\" # need to be specified\n",
    "\n",
    "# these are 10% and 90% quantiles respectively of pixel value ranges of samples created by Langevin Sampling\n",
    "# for output, these are the lower and upper limits because Langevin samples tend to contain outliers which\n",
    "# distort screen output\n",
    "lower, upper = -1.0038, 0.2826\n",
    "\n",
    "noise_scale = 1.5 # scale factor for uniform [-1,1] noise\n",
    "\n",
    "learning_rate = 6e-4 # learning rate for reconstruction optimizer\n",
    "regularizer = 0.005 # scaling factor in front of regularization term\n",
    "# this is an additional scaling factor in front of the regularization term and represents the inverse of the typical energy\n",
    "# of samples from MNIST and Langevin Sampling respectively\n",
    "# this is meant to kind of renormalize the regularization term to 1 such that the \"regularizer\" constant gets comparable to\n",
    "# the data discrepancy\n",
    "scale = 1e-8\n",
    "iteration_count = 4000 # total count of iterations for optimization\n",
    "\n",
    "output_count = 40 # output iteration step size\n",
    "\n",
    "rows, cols = 1, 1 # image grid for output\n",
    "width, height = 6, 6 # figure size\n",
    "padding = 2 # image frame padding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T12:04:56.554116Z",
     "end_time": "2023-04-04T12:04:56.558535Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/mnist_vanilla_net.pth\n"
     ]
    }
   ],
   "source": [
    "# model loading\n",
    "file = glob.glob(\"model/mnist_vanilla_net.pth\")[0]\n",
    "mnistModel = (file, torch.load(file, map_location=device))\n",
    "mnist = VanillaNet(1,image_size).to(device)\n",
    "mnist.load_state_dict(mnistModel[1]['model'])\n",
    "print(mnistModel[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T12:06:11.429218Z",
     "end_time": "2023-04-04T12:06:11.729348Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get original image\n",
    "dataset = datasets.MNIST(\n",
    "    root=path,\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    ")\n",
    "dataloaderMNIST = torch.utils.data.DataLoader(dataset, batch_size=rows*cols, shuffle=True, drop_last=True)\n",
    "\n",
    "dataMNIST = next(iter(dataloaderMNIST))\n",
    "original = dataMNIST[0]\n",
    "\n",
    "# show image\n",
    "showimg = vutils.make_grid(original, padding=padding, normalize=True, nrow=rows, value_range=(lower,upper), scale_each=False)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(width, height)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(showimg,(1,2,0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get noise\n",
    "noise = torch.randn([cols*rows, 1, image_size, image_size], device=device)\n",
    "noise_sample = noise_scale * noise.uniform_(-1, 1).cpu()\n",
    "\n",
    "# show noise\n",
    "showimg = vutils.make_grid(noise_sample, padding=padding, normalize=True, nrow=rows, value_range=(lower,upper), scale_each=False)\n",
    "fig, _ = plt.subplots()\n",
    "fig.set_size_inches(width, height)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(showimg,(1,2,0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get corrupted\n",
    "corrupted = original+noise_sample\n",
    "\n",
    "# show corrupted\n",
    "showimg = vutils.make_grid(corrupted, padding=padding, normalize=True, nrow=rows, value_range=(lower,upper), scale_each=False)\n",
    "fig, _ = plt.subplots()\n",
    "fig.set_size_inches(width, height)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(showimg,(1,2,0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preparations for optimization\n",
    "corrupted_copy = corrupted.clone().to(device)\n",
    "x = torch.nn.Parameter(corrupted_copy, requires_grad=True)\n",
    "\n",
    "x_orig = original.clone().to(device)\n",
    "x_orig.requires_grad = False\n",
    "\n",
    "for p in mnist.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# define loss and optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([x], lr=learning_rate)\n",
    "\n",
    "# optimization\n",
    "for k in range(iteration_count):\n",
    "    # actual loss consists of data discrepancy and regularization term\n",
    "    y = loss(x_orig, x) + regularizer * scale * mnist(x)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # output\n",
    "    if k % output_count == 0:\n",
    "        print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# final results\n",
    "data = torch.zeros((3,1,64,64))\n",
    "data[0] = original\n",
    "data[1] = corrupted\n",
    "data[2] = x.cpu()\n",
    "showimg = vutils.make_grid(data, padding=padding, normalize=True, nrow=3*rows*cols, value_range=(lower,upper), scale_each=False)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(width*3, height)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original | corrupted | reconstructed\")\n",
    "plt.imshow(np.transpose(showimg,(1,2,0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
