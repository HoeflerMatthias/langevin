{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torchvision.utils as vutils\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "\n",
    "# custom\n",
    "from VanillaNet import VanillaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# constants and declarations\n",
    "image_size = 64 # 64x64px\n",
    "dimension = image_size ** 2\n",
    "channels = 1 # grey scale\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "path = \"\" # need to be specified\n",
    "\n",
    "# these are 10% and 90% quantiles respectively of pixel value ranges of samples created by Langevin Sampling\n",
    "# for output, these are the lower and upper limits because Langevin samples tend to contain outliers which\n",
    "# distort screen output\n",
    "lower, upper = -1.0038, 0.2826\n",
    "\n",
    "noise_scale = 1.5 # scale factor for uniform [-1,1] noise\n",
    "\n",
    "learning_rate = 5e-3 # learning rate for reconstruction optimizer\n",
    "weight_decay = 0.0 # weight decay for optimizer\n",
    "\n",
    "iteration_count = 2500 # total count of iterations for optimization\n",
    "\n",
    "output_count = 40 # output iteration step size\n",
    "\n",
    "rows, cols = 1, 1 # image grid for output\n",
    "width, height = 6, 6 # figure size\n",
    "padding = 2 # image frame padding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model loading\n",
    "file = glob.glob(\"model/mnist_vanilla_net.pth\")[0]\n",
    "mnistModel = (file, torch.load(file, map_location=device))\n",
    "mnist = VanillaNet(1,image_size).to(device)\n",
    "mnist.load_state_dict(mnistModel[1]['model'])\n",
    "print(mnistModel[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get original image\n",
    "dataset = datasets.MNIST(\n",
    "    root=path,\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    ")\n",
    "dataloaderMNIST = torch.utils.data.DataLoader(dataset, batch_size=rows*cols, shuffle=True, drop_last=True)\n",
    "\n",
    "dataMNIST = next(iter(dataloaderMNIST))\n",
    "original = dataMNIST[0]\n",
    "\n",
    "# show image\n",
    "showimg = vutils.make_grid(original, padding=padding, normalize=True, nrow=rows, value_range=(lower,upper), scale_each=False)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(width, height)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(showimg,(1,2,0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get mask\n",
    "mask = torch.ones_like(original, device=device)\n",
    "mask[0,0,10:35,15:55] = 0\n",
    "\n",
    "# show mask\n",
    "showimg = vutils.make_grid(mask.cpu(), padding=padding, normalize=True, nrow=rows, value_range=(lower,upper), scale_each=False)\n",
    "fig, _ = plt.subplots()\n",
    "fig.set_size_inches(width, height)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(showimg,(1,2,0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get masked\n",
    "masked_image = original * mask\n",
    "\n",
    "# show masked\n",
    "showimg = vutils.make_grid(masked_image.cpu(), padding=padding, normalize=True, nrow=rows, value_range=(lower,upper), scale_each=False)\n",
    "fig, _ = plt.subplots()\n",
    "fig.set_size_inches(width, height)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(showimg,(1,2,0)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define restriced model: only input inside mask will be considered\n",
    "class Surrogate(nn.Module):\n",
    "    def __init__(self, net: VanillaNet, mask: torch.tensor, values: torch.tensor):\n",
    "        super(Surrogate, self).__init__()\n",
    "\n",
    "        self.net = net\n",
    "        self.mask = mask\n",
    "        self.values = values\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net((1-self.mask) * x + self.mask * self.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preparations for optimization\n",
    "noise = torch.randn([cols*rows, 1, image_size, image_size], device=device)\n",
    "start_image = original.clone() * mask.clone() + noise_scale * noise.uniform_(-1, 1) * (1-mask)\n",
    "x = torch.nn.Parameter(start_image, requires_grad=True)\n",
    "mask.requires_grad=False\n",
    "original.requires_grad=False\n",
    "\n",
    "surrogate = Surrogate(mnist, mask, original).to(device)\n",
    "\n",
    "for p in surrogate.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam([x], lr=learning_rate, weight_decay = weight_decay)\n",
    "for k in range(iteration_count):\n",
    "    y = surrogate(x)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if k % output_count == 0:\n",
    "        print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
